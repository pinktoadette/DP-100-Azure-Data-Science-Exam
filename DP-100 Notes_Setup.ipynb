{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notebook mainly focuses on terminoloy on Azure, methods available and process\n",
    "There is no machine learning calculation or model, any modeling will be denoted as model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Getting Started</h3>\n",
    "1.\tSetting Up Machine<br>\n",
    "    a.\tGo to Azure portal<br>\n",
    "    b.\t+ Create a resource <br>\n",
    "        i.\tCreate a new Machine Learning resource<br>\n",
    "        ii.\tWorkspace name<br>\n",
    "        iii.\tSubscription<br>\n",
    "        iv.\tResource group<br>\n",
    "        v.\tLocation<br>\n",
    "    c.\tLaunch Azure Machine Learning studio ml.azure.com<br>\n",
    "2.\tCreate compute instance<br>\n",
    "<img src=\"./images/Picture1.png\"/>\n",
    "\n",
    "On the Compute Instances tab, if you already have a compute instance, start it; otherwise create a new compute instance with the following settings:\n",
    "<ul>\n",
    "    <li>Virtual Machine type: CPU</li>\n",
    "    <li>Virtual Machine size: Standard_DS11_v2</li>\n",
    "    <li>Compute name: enter a unique name</li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "<img src=\"./images/Picture2.png\"/>\n",
    "\n",
    "Clone a ml-basics repo\n",
    "1.\tLaunch jupyterlab\n",
    "2.\tOpen terminal\n",
    "3.\tThen run bash\n",
    "cd Users\n",
    "git clone https://github.com/microsoftdocs/ml-basics\n",
    "4.\tThe files should all be there\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a production environment, you'd typically set the minimum number of nodes value to 0 so that compute is only started when it is needed. However, compute can take a while to start, so to reduce the amount of time you spend waiting for it in this module, you've initialized it with two permanently running nodes. <br>\n",
    "If you decide not to complete this module, be sure to stop your compute instance, edit the compute cluster to reset the minimum number of nodes to 0, and delete the inference cluster in order to avoid leaving your compute running and incurring unnecessary charges to your Azure subscription. Alternatively, if you're finished exploring Azure Machine Learning, delete the entire resource group in your Azure subscription.<br>\n",
    "\n",
    "Difference between\n",
    "<br>•\tcompute instances\n",
    "<br>•\t<u>compute clusters</u>: creates a single or multi-node compute. The compute executes in a containerized environment and packages your model dependencies in a docker container.\n",
    "<br>•\t<u>inference clusters</u>: deploy inference pipeline as real-time. Inference is the phase where the deployed model is used to make predictions.\n",
    "\n",
    "<h4>Clean up</h4>\n",
    "Emphasizes on clean up.\n",
    "Prevents unnecessary overcharges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>Workspace</h3>\n",
    "There are several ways to create workspace.\n",
    "<ol>\n",
    "    <li>Using azure portal, like above.</li>\n",
    "    <li>Use azure ML python SDK</li>\n",
    "    <li><code>from azureml.core import Workspace<br>\n",
    "    ws = Workspace.create(name='aml-workspace', \n",
    "                      subscription_id='123456-abc-123...',\n",
    "                      resource_group='aml-resources',\n",
    "                      create_resource_group=True,\n",
    "                      location='eastus'\n",
    "        )</code>\n",
    "    </li>\n",
    "    <li>Use CLI <br><code>az ml workspace create -w 'aml-workspace' -g 'aml-resources'</code>\n",
    "    <br>-w name -g R group\n",
    "    </li>\n",
    "    <li>Azure Resource Manager template</li>\n",
    "</ol>\n",
    "create: Name, Sub, Create, R group, location\n",
    "<br>You can also import a config file named `config.json` with the properties:\n",
    "<br><code>{\n",
    "    \"subscription_id\": \"1234567-abcde-890-fgh...\",\n",
    "    \"resource_group\": \"aml-resources\",\n",
    "    \"workspace_name\": \"aml-workspace\"\n",
    "}</code>\n",
    "        <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice this is .get not .create\n",
    "from azureml.core import Workspace \n",
    "\n",
    "ws = Workspace.get(name='practice1', \n",
    "                      subscription_id='5c2f11df-87b0-4d35-8e09-fbadc191e71e', \n",
    "                      resource_group='exam_practice1' )\n",
    "for compute_name in ws.compute_targets:\n",
    "    compute = ws.compute_targets[compute_name]\n",
    "    print(compute.name, \":\", compute.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Experiments</h3>\n",
    "Experiment can be run multiple times, width different data, code or settings. \n",
    "\n",
    "Every experiment contains log files. To output the log, just `print` the statements to the log.However, if you want to record named metrics for comparison across runs, you can do so by using the Run object; which provides a range of logging functions specifically for this purpose. These include:\n",
    "<ul>\n",
    "    <li>log: Record a single named value.</li>\n",
    "    <li>log_list: Record a named list of values.</li>\n",
    "    <li>log_row: Record a row with multiple columns.</li>\n",
    "    <li>log_table: Record a dictionary as a table.</li>\n",
    "    <li>log_image: Record an image file or a plot.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates experiement, then records number of observation in a csv file\n",
    "\n",
    "from azureml.core import Experiment\n",
    "import pandas as pd\n",
    "\n",
    "# Create an Azure ML experiment in your workspace\n",
    "experiment = Experiment(workspace = ws, name = 'my-experiment')\n",
    "\n",
    "# Start logging data from the experiment\n",
    "run = experiment.start_logging()\n",
    "\n",
    "# load the dataset and count the rows\n",
    "data = pd.read_csv('data.csv')\n",
    "row_count = (len(data))\n",
    "\n",
    "# Log the row count\n",
    "run.log('observations', row_count)\n",
    "\n",
    "# Complete the experiment\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Log Metrics:<br>\n",
    "from azureml.widgets import RunDetails\n",
    "<br>View logs with either of these\n",
    "<ul>\n",
    "    <li>RunDetails(run).show()</li>\n",
    "    <li>run.get_metrics()<br>\n",
    "        print(json.dumps(metrics, indent=2))</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Log Output files:<br>\n",
    "Often these are trained machine learning models, but you can save any sort of file and make it available as an output of your experiment run. The output files of an experiment are saved in its outputs folder.\n",
    " <br>\n",
    "<br>View logs with either of these\n",
    "<ul>\n",
    "    <li>run.upload_file(name='outputs/sample.csv', path_or_stream='./sample.csv')</li>\n",
    "    <li>f = run.get_file_names()<br>\n",
    "        print(json.dumps(f, indent=2))</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Script files:<br>\n",
    "An experiment script is just a Python code file that contains the code you want to run in the experiment. To access the experiment run context (which is needed to log metrics) the script must import the `azureml.core.Run` class and call its `get_context method`. \n",
    " <br>\n",
    "<br>View logs with either of these\n",
    "<ul>\n",
    "    <li>run.upload_file(name='outputs/sample.csv', path_or_stream='./sample.csv')</li>\n",
    "    <li>f = run.get_file_names()<br>\n",
    "        print(json.dumps(f, indent=2))</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment.py file\n",
    "from azureml.core import Run\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the diabetes dataset\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Count the rows and log the result\n",
    "row_count = (len(data))\n",
    "run.log('observations', row_count)\n",
    "\n",
    "# Save a sample of the data\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "data.sample(100).to_csv(\"outputs/sample.csv\", index=False, header=True)\n",
    "\n",
    "# Complete the run\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To run a script as an experiment, you must define a script configuration that defines the script to be run and the Python environment in which to run it. This is implemented by using a `ScriptRunConfig` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment, ScriptRunConfig\n",
    "\n",
    "# Create a script config and run about experiment.py file\n",
    "script_config = ScriptRunConfig(source_directory=experiment_folder,\n",
    "                                script='experiment.py') \n",
    "\n",
    "# submit the experiment\n",
    "experiment = Experiment(workspace = ws, name = 'my-experiment')\n",
    "run = experiment.submit(config=script_config)\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h3>Training Script</h3>\n",
    "You can use a `ScriptRunConfig` to run a script-based experiment that trains a machine learning model.\n",
    "\n",
    "<br>Say you have a model.py, it needs to be trained, you can call `ScriptRunConfig`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment, ScriptRunConfig, Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "# Create a Python environment for the experiment\n",
    "sklearn_env = Environment(\"sklearn-env\")\n",
    "\n",
    "# Ensure the required packages are installed\n",
    "packages = CondaDependencies.create(conda_packages=['scikit-learn','pip'],\n",
    "                                    pip_packages=['azureml-defaults'])\n",
    "sklearn_env.python.conda_dependencies = packages\n",
    "\n",
    "# Create a script config <HERE you call your model>\n",
    "script_config = ScriptRunConfig(source_directory='training_folder',\n",
    "                                script='model.py',\n",
    "                                environment=sklearn_env) \n",
    "\n",
    "# Submit the experiment\n",
    "experiment = Experiment(workspace=ws, name='training-experiment')\n",
    "run = experiment.submit(config=script_config)\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also add arguments to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a script config\n",
    "script_config = ScriptRunConfig(source_directory='training_folder',\n",
    "                                script='model.py',\n",
    "                                arguments = ['--reg-rate', 0.1],\n",
    "                                environment=sklearn_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****You want to use a script-based experiment to train a PyTorch model, setting the batch size and learning rate hyperparameters to specified values each time the experiment runs. What should you do? Add arguments for batch size and learning rate to the script, and set them in the arguments property of the ScriptRunConfig.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Retrieving Model</h4>\n",
    "After an experiment run has completed, you can use the run objects get_file_names method to list the files generated. Standard practice is for scripts that train models to save them in the run's outputs folder.\n",
    "<br>\n",
    "You can also use the run object's `download_file` and `download_files` methods to download output files to the local file system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"run\" is a reference to a completed experiment run\n",
    "\n",
    "# List the files generated by the experiment\n",
    "for file in run.get_file_names():\n",
    "    print(file)\n",
    "\n",
    "# Download a named file\n",
    "run.download_file(name='outputs/model.pkl', output_file_path='model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Register a model</h4>\n",
    "Model registration enables you to track multiple versions of the model and retrive models for inference.  Registering a model with the same name as an existing model automatically creates a new version of the model, starting with 1 and increasing in units of 1.\n",
    "<br>\n",
    "TWO WAYS:<br>\n",
    "\n",
    "To register a model from a local file, you can use the register method of the Model object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Model\n",
    "\n",
    "model = Model.register(workspace=ws,\n",
    "                       model_name='classification_model',\n",
    "                       model_path='model.pkl', # local path\n",
    "                       description='A classification model',\n",
    "                       tags={'data-format': 'CSV'},\n",
    "                       model_framework=Model.Framework.SCIKITLEARN,\n",
    "                       model_framework_version='0.20.3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using run references, you can also register the model\n",
    "run.register_model( model_name='classification_model',\n",
    "                    model_path='outputs/model.pkl', # run outputs path\n",
    "                    description='A classification model',\n",
    "                    tags={'data-format': 'CSV'},\n",
    "                    model_framework=Model.Framework.SCIKITLEARN,\n",
    "                    model_framework_version='0.20.3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****You have run an experiment to train a model. You want the model to be stored in the workspace, and available to other experiments and published services. What should you do? Register the model in the workspace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Viewing the Model\n",
    "<code>from azureml.core import Model\n",
    "<br>\n",
    "for model in Model.list(ws):\n",
    "    # Get model name and auto-generated version\n",
    "    print(model.name, 'version:', model.version)</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
